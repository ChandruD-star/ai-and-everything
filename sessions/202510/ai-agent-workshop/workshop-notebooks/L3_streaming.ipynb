{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "<img src=\"./assets/LC_streaming.png\">\n",
    "\n",
    "Streaming reduces the latency between generating data and the user receiving it.\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f0f22c-9724-46ce-baf3-60a2de701fb3",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b76bab7-fa52-46f4-86bc-b157067e0168",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2fcfd93-0004-4ff1-9b60-0b21baf68c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLLAMA_HOST_URL=http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"granite4:latest\",\n",
    "    temperature=0,\n",
    "    base_url=os.environ['OLLAMA_HOST_URL']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, here's one for you:\n",
      "\n",
      "Why don't programmers like nature?\n",
      "\n",
      "Because of all the bugs in source code. \n",
      "\n",
      "And if they do like it, why do they have trouble with recursion? Because to understand recursion, you need to understand recursion!\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values\n",
    "You have seen this streaming mode in our examples so far. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a Dad joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, here's a classic dad joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a Dad joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## messages\n",
    "Messages stream data token by token - the lowest latency possible. This is perfect for interactive applications like chatbots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the heart of a home, where laughter is key,\n",
      "Lives a family so fun, you'd want to be free.\n",
      "With love as their compass, and kindness their guide,\n",
      "They navigate life with joy by their side.\n",
      "\n",
      "Mom, she's the chef, with recipes divine,\n",
      "Crafting meals that make your taste buds shine.\n",
      "Dad, he's the mechanic, fixing things with care,\n",
      "But when it comes to his family, there's no need for repair.\n",
      "\n",
      "The kids, oh they're a bundle of energy and cheer,\n",
      "With dreams as big as their love for them here.\n",
      "They play games till dusk, under the starry night sky,\n",
      "Their laughter echoes through every room, making everything right.\n",
      "\n",
      "Grandma with her tales from days gone by,\n",
      "Her wisdom like gold, shining bright in the eye.\n",
      "She teaches lessons of life, wrapped in stories old,\n",
      "Of courage and kindness, standing tall and bold.\n",
      "\n",
      "And when storms come rolling, dark clouds may loom,\n",
      "But together they stand strong, their love ever true.\n",
      "For in this family, there's no room for strife,\n",
      "Just understanding, respect, and endless delight.\n",
      "\n",
      "So here's to the families who make life complete,\n",
      "Where every member matters, and love is so sweet.\n",
      "May your days be filled with joyous laughter and cheer,\n",
      "And may you always find happiness near."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a family friendly poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!\n",
    "Streaming generally means delivering information to the user before the final result is ready. There are many cases where this is useful. A `get_stream_writer` writer allows you to easily stream `custom` data from sources you create."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='d7c32a76-1958-4875-b6dd-c6cc1543ee6e')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='d7c32a76-1958-4875-b6dd-c6cc1543ee6e'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:56:36.586979Z', 'done': True, 'done_reason': 'stop', 'total_duration': 485040709, 'load_duration': 48817709, 'prompt_eval_count': 172, 'prompt_eval_duration': 182606583, 'eval_count': 27, 'eval_duration': 245904667, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--edf721c9-b98e-478c-85a6-e58f5738ae2d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'ca2542ea-089a-4a0c-b4f2-c607a140a654', 'type': 'tool_call'}], usage_metadata={'input_tokens': 172, 'output_tokens': 27, 'total_tokens': 199})]})\n",
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='d7c32a76-1958-4875-b6dd-c6cc1543ee6e'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:56:36.586979Z', 'done': True, 'done_reason': 'stop', 'total_duration': 485040709, 'load_duration': 48817709, 'prompt_eval_count': 172, 'prompt_eval_duration': 182606583, 'eval_count': 27, 'eval_duration': 245904667, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--edf721c9-b98e-478c-85a6-e58f5738ae2d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'ca2542ea-089a-4a0c-b4f2-c607a140a654', 'type': 'tool_call'}], usage_metadata={'input_tokens': 172, 'output_tokens': 27, 'total_tokens': 199}), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='01d340b3-ebaa-4b2f-bf9b-915952c25a93', tool_call_id='ca2542ea-089a-4a0c-b4f2-c607a140a654')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='d7c32a76-1958-4875-b6dd-c6cc1543ee6e'), AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:56:36.586979Z', 'done': True, 'done_reason': 'stop', 'total_duration': 485040709, 'load_duration': 48817709, 'prompt_eval_count': 172, 'prompt_eval_duration': 182606583, 'eval_count': 27, 'eval_duration': 245904667, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--edf721c9-b98e-478c-85a6-e58f5738ae2d-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'SF'}, 'id': 'ca2542ea-089a-4a0c-b4f2-c607a140a654', 'type': 'tool_call'}], usage_metadata={'input_tokens': 172, 'output_tokens': 27, 'total_tokens': 199}), ToolMessage(content=\"It's always sunny in SF!\", name='get_weather', id='01d340b3-ebaa-4b2f-bf9b-915952c25a93', tool_call_id='ca2542ea-089a-4a0c-b4f2-c607a140a654'), AIMessage(content='The current weather in San Francisco (SF) is **sunny** with clear skies and mild temperatures. Enjoy your day!', additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:56:36.906958Z', 'done': True, 'done_reason': 'stop', 'total_duration': 310695791, 'load_duration': 25961583, 'prompt_eval_count': 216, 'prompt_eval_duration': 38749917, 'eval_count': 26, 'eval_duration': 238719040, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--e3944bb2-caf1-44d3-a9c4-1e4ef89309b1-0', usage_metadata={'input_tokens': 216, 'output_tokens': 26, 'total_tokens': 242})]})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('custom', 'Looking up data for city: SF')\n",
      "('custom', 'Acquired data for city: SF')\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3845c067-761f-46a0-817c-2cc42066ce9a",
   "metadata": {},
   "source": [
    "## Try different modes on your own!\n",
    "Modify the stream mode and the select to produce different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92943e4f-6c17-4fa3-ad00-f86464ba66f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: SF\n",
      "Acquired data for city: SF\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
