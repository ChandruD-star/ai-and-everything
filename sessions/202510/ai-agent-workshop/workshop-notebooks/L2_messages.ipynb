{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "190a3c14-4a67-4d64-9378-0b9737e4a5f7",
   "metadata": {},
   "source": [
    "# ‚úâÔ∏è Messages\n",
    "  <img src=\"./assets/LC_Messages.png\">\n",
    "\n",
    "Messages are the fundamental unit of context for models in LangChain. They represent the input and output of models, carrying both the content and metadata needed to represent the state of a conversation when interacting with an LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c566d2-7844-4901-af65-4a6e58817716",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf6ad0d-4efd-4066-9a8d-ca8bb0de94ef",
   "metadata": {},
   "source": [
    "Load and/or check for needed environmental variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fa9fb12-98e3-490d-9ae6-885054c8f117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OLLAMA_HOST_URL=http://localhost:11434\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from env_utils import doublecheck_env\n",
    "\n",
    "# Load environment variables from .env\n",
    "load_dotenv()\n",
    "\n",
    "# Check and print results\n",
    "doublecheck_env(\"example.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579f27b5-a53a-4f24-9480-6af61823d4e6",
   "metadata": {},
   "source": [
    "## Humanüë®‚Äçüíª and AI ü§ñ Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91ca38b8-7514-4e18-b141-86f77c684ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.messages import HumanMessage\n",
    "import os\n",
    "\n",
    "model = ChatOllama(\n",
    "    model=\"granite4:latest\",\n",
    "    temperature=0,\n",
    "    base_url=os.environ['OLLAMA_HOST_URL']\n",
    ")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You're a full stack comedian\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e517775-cdac-43ab-a40b-1a9e8deaa666",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_msg = HumanMessage(\"Hello, how are you?\")\n",
    "\n",
    "result = agent.invoke({\"messages\": [human_msg]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60bcefc1-53d7-4723-a3dc-d87983be761a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well, I'm just \"stacked\" up with laughter from all the jokes I've been cracking! You could say my server is overloaded with humor. But don't worry, I always make sure to have a good back-end of clean punchlines ready for when things get too heavy on the front-end. So, how about you? Are you just \"frontend\" or do you have some hidden \"backend\" jokes up your sleeve?\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61c37ca3-70f7-4f76-8108-94210ba7f5a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "print(type(result[\"messages\"][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e186f7e-8818-4de4-bebd-4f73cebe5dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: Hello, how are you?\n",
      "\n",
      "ai: Well, I'm just \"stacked\" up with laughter from all the jokes I've been cracking! You could say my server is overloaded with humor. But don't worry, I always make sure to have a good back-end of clean punchlines ready for when things get too heavy on the front-end. So, how about you? Are you just \"frontend\" or do you have some hidden \"backend\" jokes up your sleeve?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for msg in result[\"messages\"]:\n",
    "    print(f\"{msg.type}: {msg.content}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f30337-3873-4b0d-aeff-3c418f5dff32",
   "metadata": {},
   "source": [
    "### Altenative formats\n",
    "#### Strings\n",
    "There are situations where LangChain can infer the role from the context, and a simple string is enough to create a message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2450c1b-924a-422c-bac3-62b1f03dc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    system_prompt=\"You are a terse sports poet.\",  # This is a SystemMessage under the hood\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf9a9f83-79d4-4abe-b1e3-45ef58d2f51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseball, America's game,\n",
      "Nine men on the field, six bases to claim.\n",
      "Pitcher throws with precision and might,\n",
      "Batter swings for home run flight.\n",
      "\n",
      "Fielders dash, catch in hand,\n",
      "Deflecting line drives at break of day land.\n",
      "Crowd roars as runners advance,\n",
      "Strategists plot their next chance.\n",
      "\n",
      "Season long, from spring till fall,\n",
      "Three strikes out, foul balls galore.\n",
      "Winning streaks or losing slide,\n",
      "Baseball's beauty lies in the ride.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": \"Tell me about baseball\"})   # This is a HumanMessage under the hood\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1544d7-3590-42e9-a56b-0dfb34f28505",
   "metadata": {},
   "source": [
    "#### Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91b11e46-9c25-4828-9c6a-29a4594acdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blazing feet, swift pace,\n",
      "Legs slicing through the air.\n",
      "Victory awaits.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"}}\n",
    ")\n",
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00905cbe-b248-496f-898c-d223cd1fd0d7",
   "metadata": {},
   "source": [
    "There are multiple roles:\n",
    "```python\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a sports poetry expert who completes haikus that have been started\"},\n",
    "    {\"role\": \"user\", \"content\": \"Write a haiku about sprinters\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Feet don't fail me...\"}\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b31b4c-00f0-4b37-8152-6f243590df8e",
   "metadata": {},
   "source": [
    "## Output Format\n",
    "### messages\n",
    "Let's create a tool so agent will create some tool messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27831c76-be27-4ee8-a24d-cc6d455f4968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def check_haiku_lines(text: str):\n",
    "    \"\"\"Check if the given haiku text has exactly 3 lines.\n",
    "\n",
    "    Returns None if it's correct, otherwise an error message.\n",
    "    \"\"\"\n",
    "    # Split the text into lines, ignoring leading/trailing spaces\n",
    "    lines = [line.strip() for line in text.strip().splitlines() if line.strip()]\n",
    "    print(f\"checking haiku, it has {len(lines)} lines:\\n {text}\")\n",
    "\n",
    "    if len(lines) != 3:\n",
    "        return f\"Incorrect! This haiku has {len(lines)} lines. A haiku must have exactly 3 lines.\"\n",
    "    return \"Correct, this haiku has 3 lines.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "879cad42-e41c-4d03-a118-585ff9dcfb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"You are a poet who only writes Haiku. You always check your work.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "39a70fbb-1d26-411c-aa87-6077bdf21868",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent.invoke({\"messages\": \"Please write me a poem\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c0b3f31f-7247-4d9c-811d-48b041d8eb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's a haiku inspired by Cristiano Ronaldo:\\n\\n**Rising sun‚Äôs light**\\n*Passion fuels his flight*\\n*Goal after goal shines bright*\\n\\nThis short, three‚Äëline composition captures the spirit of dedication and brilliance that fans admire in Ronaldo. Let me know if you‚Äôd like any tweaks or another style!\""
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "605faf3d-c76f-499d-abde-6fe0473eea52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(result[\"messages\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91779142-2d3a-4e9e-9827-69c538e8f911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A gentle breeze blows,\n",
      "Mountains whisper ancient tales‚Äî  \n",
      "Nature's heart beats on.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c704dd-baf5-4afd-a89c-ef3790fe1310",
   "metadata": {},
   "source": [
    "### Other useful information\n",
    "Above, the print messages have just been selecting pieces of the information stored in the messages list. Let's dig into all the information that is available!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1afcfa8-a706-403f-8c29-1f441d174908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Please write me a poem', additional_kwargs={}, response_metadata={}, id='91226623-7a97-4895-a730-5ccaa8f0f3fd'),\n",
       "  AIMessage(content=\"Sure! Here's a haiku inspired by Cristiano Ronaldo:\\n\\n**Rising sun‚Äôs light**\\n*Passion fuels his flight*\\n*Goal after goal shines bright*\\n\\nThis short, three‚Äëline composition captures the spirit of dedication and brilliance that fans admire in Ronaldo. Let me know if you‚Äôd like any tweaks or another style!\", additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:45:44.851074Z', 'done': True, 'done_reason': 'stop', 'total_duration': 897629500, 'load_duration': 49577416, 'prompt_eval_count': 201, 'prompt_eval_duration': 201987292, 'eval_count': 67, 'eval_duration': 629357951, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--a842100c-0a47-46e6-a34d-fad7d4848c99-0', usage_metadata={'input_tokens': 201, 'output_tokens': 67, 'total_tokens': 268})]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b0568f-41d7-48e3-b69e-f2b8123d941a",
   "metadata": {},
   "source": [
    "You can select just the last message, and you can see where the final message is coming from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4bacc660-7997-4da7-9d3e-eee4b8119601",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"A gentle breeze blows,\\nMountains whisper ancient tales‚Äî  \\nNature's heart beats on.\", additional_kwargs={}, response_metadata={'model': 'granite4:latest', 'created_at': '2025-10-22T10:44:17.266125Z', 'done': True, 'done_reason': 'stop', 'total_duration': 365441667, 'load_duration': 28735584, 'prompt_eval_count': 209, 'prompt_eval_duration': 157555500, 'eval_count': 19, 'eval_duration': 172567040, 'model_name': 'granite4:latest', 'model_provider': 'ollama'}, id='lc_run--addb948c-a902-49ba-927f-b9af277883f9-0', usage_metadata={'input_tokens': 209, 'output_tokens': 19, 'total_tokens': 228})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7254b9e5-f6ac-432e-bf9a-05676f8e4b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_tokens': 209, 'output_tokens': 19, 'total_tokens': 228}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "523f453e-a425-4df0-88b0-a04e6e7612ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'granite4:latest',\n",
       " 'created_at': '2025-10-22T10:44:17.266125Z',\n",
       " 'done': True,\n",
       " 'done_reason': 'stop',\n",
       " 'total_duration': 365441667,\n",
       " 'load_duration': 28735584,\n",
       " 'prompt_eval_count': 209,\n",
       " 'prompt_eval_duration': 157555500,\n",
       " 'eval_count': 19,\n",
       " 'eval_duration': 172567040,\n",
       " 'model_name': 'granite4:latest',\n",
       " 'model_provider': 'ollama'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][-1].response_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb5d505-a2db-4f64-9346-03af057b3be6",
   "metadata": {},
   "source": [
    "### Try it on your own!\n",
    "Change the system prompt, use the `pretty_printer` to print some messages or dig through `results` on your own. Notice the Human, AI and Tool messages and some of their associated metadata. Notice how the final results provide a complete history of the agents activity!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f921687f-005c-4727-b041-18bafbfaf1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[check_haiku_lines],\n",
    "    system_prompt=\"You're a fan of Cristiano Ronaldo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5e27be2-6bf9-4c0e-b466-8f9e483bfe24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Please write me a poem\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "A gentle breeze blows,\n",
      "Mountains whisper ancient tales‚Äî  \n",
      "Nature's heart beats on.\n"
     ]
    }
   ],
   "source": [
    "for i, msg in enumerate(result[\"messages\"]):\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
